{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6eda832-74e3-4fad-aec8-3a4a1bbaf712",
   "metadata": {},
   "source": [
    "## World's Simplest Web Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614d76d-a793-4f62-98f7-3702f9c1107f",
   "metadata": {},
   "source": [
    "First the program makes a connection to port 80 on the server www.py4e.com.\n",
    "\n",
    "Since our program is playing the role of the “web browser”, the HTTP protocol\n",
    "says we must send the GET command followed by a blank line.\n",
    "\n",
    "Once we send that blank line, we write a loop that receives data in 512-character\n",
    "chunks from the socket and prints the data out until there is no more data to read\n",
    "(i.e., the recv() returns an empty string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5deb972-10ae-43be-a335-a7d2601bdaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Mon, 14 Nov 2022 19:47:54 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"a7-54f6609245537\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 167\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "#socket1.py\n",
    "\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(20)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea66675-1c51-493d-9c8d-d91ee56c257f",
   "metadata": {},
   "source": [
    "## Retrieving an image over HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2675dc-7e35-4ebd-b329-3254392ae422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120 5120\n",
      "5120 10240\n",
      "5120 15360\n",
      "5120 20480\n",
      "5120 25600\n",
      "5120 30720\n",
      "5120 35840\n",
      "5120 40960\n",
      "5120 46080\n",
      "5120 51200\n",
      "5120 56320\n",
      "5120 61440\n",
      "5120 66560\n",
      "5120 71680\n",
      "5120 76800\n",
      "5120 81920\n",
      "5120 87040\n",
      "5120 92160\n",
      "5120 97280\n",
      "5120 102400\n",
      "5120 107520\n",
      "5120 112640\n",
      "5120 117760\n",
      "5120 122880\n",
      "5120 128000\n",
      "5120 133120\n",
      "5120 138240\n",
      "5120 143360\n",
      "5120 148480\n",
      "5120 153600\n",
      "5120 158720\n",
      "5120 163840\n",
      "5120 168960\n",
      "5120 174080\n",
      "5120 179200\n",
      "5120 184320\n",
      "5120 189440\n",
      "5120 194560\n",
      "5120 199680\n",
      "5120 204800\n",
      "5120 209920\n",
      "5120 215040\n",
      "5120 220160\n",
      "5120 225280\n",
      "5120 230400\n",
      "208 230608\n",
      "Header length 394\n",
      "HTTP/1.1 200 OK\n",
      "Date: Mon, 14 Nov 2022 19:48:47 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Mon, 15 May 2017 12:27:40 GMT\n",
      "ETag: \"38342-54f8f2e5b6277\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 230210\n",
      "Vary: Accept-Encoding\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: image/jpeg\n"
     ]
    }
   ],
   "source": [
    "#urljpeg.py\n",
    "\n",
    "import socket\n",
    "import time\n",
    "\n",
    "HOST = 'data.pr4e.org'\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((HOST, PORT))\n",
    "\n",
    "#send string as byte literal using prefix \"b\"\n",
    "mysock.sendall(b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if (len(data) < 1): break\n",
    "    time.sleep(0.25)\n",
    "    count = count + len(data)\n",
    "    print(len(data), count)\n",
    "    picture = picture + data\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header (2 CRLF)\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print('Header length', pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# Skip past the header and save the picture data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9559034-19e3-4013-af3e-0270d28885f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieving web pages with urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b9eb2-bd11-45b9-a2bf-a0cd17ad384f",
   "metadata": {},
   "source": [
    "Using urllib, you can treat a web page much like a file. \n",
    "\n",
    "You simply indicate which web page you would like to retrieve and urllib handles all of the HTTP protocol and header details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f07df0-6e1a-42cd-b3a2-03421e9bff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "#urllib1.py\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "# The headers are still sent, but the urllib code consumes the \n",
    "# headers and only returns\n",
    "the data to us.\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644a05de-5ede-49f1-a524-52b2cbf5c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "#urlwords.py\n",
    "# a program to retrieve the data for romeo.txt and\n",
    "# compute the frequency of each word in the file\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d24140d-8285-4917-9873-f11cb3a1e163",
   "metadata": {},
   "source": [
    "## Parsing HTML using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4f00cb-3e9a-4060-80c5-438865124426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter -  http://www.dr-chuck.com/page1.htm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "#urlregex.py\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import re\n",
    "\n",
    "#  http://www.dr-chuck.com/page1.htm\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url).read()\n",
    "links = re.findall(b'href=\"(http://.*?)\"', html)\n",
    "for link in links:\n",
    "    print(link.decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc28fa2-0f15-4e5d-aab4-9927dad79abc",
   "metadata": {},
   "source": [
    "## Parsing HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a1c00a-5ba2-4197-81e1-11672cbf2aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1.htm\n",
      "there are 1 paragraph tags\n",
      "<p>\n",
      "If you like, you can switch back to the \n",
      "<a href=\"page1.htm\">\n",
      "First Page</a>.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "#urllinks.py\n",
    "\n",
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "#url = input('Enter - ')\n",
    "url = \"http://www.dr-chuck.com/page2.htm\"\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))\n",
    "    \n",
    "tags = soup.find_all('p')\n",
    "print(\"there are %d paragraph tags\" % len(tags))\n",
    "for tag in tags:\n",
    "    print(tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43300901-5e32-46ab-8823-2ec7acafb7ea",
   "metadata": {},
   "source": [
    "## Reading binary files using urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa28c98-8504-4b45-ad43-b4d3589a9614",
   "metadata": {},
   "source": [
    "This program reads all of the data in at once across the network and stores it in the\n",
    "variable img in the main memory of your computer, then opens the file cover.jpg\n",
    "and writes the data out to your disk. \n",
    "\n",
    "This will work if the size of the file is less\n",
    "than the size of the memory of your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e72e943-4f7e-42ef-b57d-a51ae7cad9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curl1.py\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg').read()\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "fhand.write(img)\n",
    "fhand.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c47687-4a50-44a2-aa1d-7c49b66dfda9",
   "metadata": {},
   "source": [
    "If the file is a large file, this program may crash or at least\n",
    "run extremely slowly when your computer runs out of memory. In order to avoid\n",
    "running out of memory, we retrieve the data in blocks (or buffers) and then write\n",
    "each block to your disk before retrieving the next block. This way the program can\n",
    "read any size file without using up all of the memory you have in your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c665fd06-40e2-4a47-bf6e-c68eefce4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230210 characters copied.\n"
     ]
    }
   ],
   "source": [
    "#curl2.py\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg')\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "size = 0\n",
    "while True:\n",
    "    info = img.read(100000)\n",
    "    if len(info) < 1: break\n",
    "    size = size + len(info)\n",
    "    fhand.write(info)\n",
    "\n",
    "print(size, 'characters copied.')\n",
    "fhand.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
